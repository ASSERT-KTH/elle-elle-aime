{
  "files": 1, 
  "nb_test": 466, 
  "nb_error": 0, 
  "classification": {
    "singleLine": false
  }, 
  "failing_tests": [
    "org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest"
  ], 
  "patch": "diff --git a/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java b/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java\nindex e1e8a535a1..bea03c6bd9 100644\n--- a/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java\n+++ b/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java\n@@ -75,6 +75,7 @@\n import static com.google.common.collect.Iterables.toArray;\n import static com.google.common.collect.Iterables.transform;\n import static com.google.common.collect.Maps.newConcurrentMap;\n+import static com.google.common.collect.Maps.newHashMap;\n import static org.apache.jackrabbit.oak.commons.IOUtils.humanReadableByteCount;\n \n public class IndexCopier implements CopyOnReadStatsMBean, Closeable {\n@@ -111,6 +112,7 @@\n \n \n     private final Map<String, String> indexPathMapping = newConcurrentMap();\n+    private final Map<String, Set<String>> sharedWorkingSetMap = newHashMap();\n     private final Map<String, String> indexPathVersionMapping = newConcurrentMap();\n     private final ConcurrentMap<String, LocalIndexFile> failedToDeleteFiles = newConcurrentMap();\n     private final Set<LocalIndexFile> copyInProgressFiles = Collections.newSetFromMap(new ConcurrentHashMap<LocalIndexFile, Boolean>());\n@@ -131,12 +133,13 @@ public IndexCopier(Executor executor, File indexRootDir, boolean prefetchEnabled\n     public Directory wrapForRead(String indexPath, IndexDefinition definition,\n             Directory remote) throws IOException {\n         Directory local = createLocalDirForIndexReader(indexPath, definition);\n-        return new CopyOnReadDirectory(remote, local, prefetchEnabled, indexPath);\n+        return new CopyOnReadDirectory(remote, local, prefetchEnabled, indexPath, getSharedWorkingSet(definition));\n     }\n \n     public Directory wrapForWrite(IndexDefinition definition, Directory remote, boolean reindexMode) throws IOException {\n         Directory local = createLocalDirForIndexWriter(definition);\n-        return new CopyOnWriteDirectory(remote, local, reindexMode, getIndexPathForLogging(definition));\n+        return new CopyOnWriteDirectory(remote, local, reindexMode,\n+                getIndexPathForLogging(definition), getSharedWorkingSet(definition));\n     }\n \n     @Override\n@@ -237,6 +240,34 @@ private void successfullyDeleted(LocalIndexFile file, boolean fileExisted){\n         }\n     }\n \n+    /**\n+     * Provide the corresponding shared state to enable COW inform COR\n+     * about new files it is creating while indexing. This would allow COR to ignore\n+     * such files while determining the deletion candidates.\n+     *\n+     * @param defn index definition for which the directory is being created\n+     * @return a set to maintain the state of new files being created by the COW Directory\n+     */\n+    private Set<String> getSharedWorkingSet(IndexDefinition defn){\n+        String indexPath = defn.getIndexPathFromConfig();\n+\n+        if (indexPath == null){\n+            //With indexPath null the working directory would not\n+            //be shared between COR and COW. So just return a new set\n+            return new HashSet<String>();\n+        }\n+\n+        Set<String> sharedSet;\n+        synchronized (sharedWorkingSetMap){\n+            sharedSet = sharedWorkingSetMap.get(indexPath);\n+            if (sharedSet == null){\n+                sharedSet = Sets.newConcurrentHashSet();\n+                sharedWorkingSetMap.put(indexPath, sharedSet);\n+            }\n+        }\n+        return sharedSet;\n+    }\n+\n     /**\n      * Creates the workDir. If it exists then it is cleaned\n      *\n@@ -274,12 +305,17 @@ private static String getIndexPathForLogging(IndexDefinition defn){\n          */\n         private final Set<String> localFileNames = Sets.newConcurrentHashSet();\n \n-        public CopyOnReadDirectory(Directory remote, Directory local, boolean prefetch, String indexPath) throws IOException {\n+        public CopyOnReadDirectory(Directory remote, Directory local, boolean prefetch,\n+                                   String indexPath, Set<String> sharedWorkingSet) throws IOException {\n             super(remote);\n             this.remote = remote;\n             this.local = local;\n             this.indexPath = indexPath;\n+\n             this.localFileNames.addAll(Arrays.asList(local.listAll()));\n+            //Remove files which are being worked upon by COW\n+            this.localFileNames.removeAll(sharedWorkingSet);\n+\n             if (prefetch) {\n                 prefetchIndexFiles();\n             }\n@@ -549,6 +585,7 @@ public Void call() throws Exception {\n         private final CountDownLatch copyDone = new CountDownLatch(1);\n         private final boolean reindexMode;\n         private final String indexPathForLogging;\n+        private final Set<String> sharedWorkingSet;\n \n         /**\n          * Current background task\n@@ -602,12 +639,13 @@ public void run() {\n         };\n \n         public CopyOnWriteDirectory(Directory remote, Directory local, boolean reindexMode,\n-                                    String indexPathForLogging) throws IOException {\n+                                    String indexPathForLogging, Set<String> sharedWorkingSet) throws IOException {\n             super(local);\n             this.remote = remote;\n             this.local = local;\n             this.indexPathForLogging = indexPathForLogging;\n             this.reindexMode = reindexMode;\n+            this.sharedWorkingSet = sharedWorkingSet;\n             initialize();\n         }\n \n@@ -647,6 +685,7 @@ public IndexOutput createOutput(String name, IOContext context) throws IOExcepti\n             }\n             ref = new COWLocalFileReference(name);\n             fileMap.put(name, ref);\n+            sharedWorkingSet.add(name);\n             return ref.createOutput(context);\n         }\n \n@@ -723,6 +762,7 @@ public void close() throws IOException {\n \n             local.close();\n             remote.close();\n+            sharedWorkingSet.clear();\n         }\n \n         @Override\n@@ -994,7 +1034,7 @@ private boolean deleteFile(Directory dir, String fileName, boolean copiedFromRem\n         } catch (IOException e) {\n             failedToDelete(file);\n             log.debug(\"Error occurred while removing deleted file {} from Local {}. \" +\n-                    \"Attempt would be maid to delete it on next run \", fileName, dir, e);\n+                    \"Attempt would be made to delete it on next run \", fileName, dir, e);\n         }\n         return successFullyDeleted;\n     }\n", 
  "project": "jackrabbit-oak", 
  "linesAdd": 45, 
  "jira_id": "3110", 
  "nb_skipped": 3, 
  "commit": "d10362c0", 
  "nb_failure": 1, 
  "linesRem": 5
}