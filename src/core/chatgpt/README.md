# Setup

## Overview
This repo extends from [RepairThemAll](https://github.com/program-repair/RepairThemAll) and [LLM-RTA-CodeX](https://github.com/ASSERT-KTH/llm-repair-them-all), focuses on exploring the potential of ChataGPT and its improved version for program repair. We currently can support Defects4J and Refactory. You can contribute your prompt by submitting PR. You can add your prompt to [src/core/chatgpt/config/prompt_config.py](https://github.com/TomasAndersonFang/ChatGPT-Repair/blob/main/src/core/chatgpt/config/prompt_config.py).

## Prerequisite
  * git
  * Defects4J, refer to [Defects4J](https://github.com/rjust/defects4j) for configuration.
 
## Setup in localhost
  * Clone this repo
  * `cd llm-repair-them-all`
  * `cp .env_chatgpt .env` and finish setting in .env
  * Manually apply [this change](https://github.com/rjust/defects4j/pull/499) int this file `benchmarks/defects4j/framework/core/Vcs.pm`

## Configuration
Running parameters and settings should be configured in two different places.\
* `.env`: Here you need to setup Java home path, Defects4J home path, your openai api key and other settings.\
* `src/config.py`: This is a legacy file where you can configure Java params, working directory etc. Some of parameters can be moved to `.env` since the envfile has been loaded at the beginning of this file.

# Process
You can use this project by runing `./run.sh`. You can also specific your requirments by changing the parameters in `run.sh`. We describe some key parameters in the following.
## Parameters
- `-b`: The benchmark you want to use. Now we can support Defects4J and Refactory.
- `-m`: The version of ChatGPT you want to use.
- `-or`: By setting it to `True`, you can only request ChatGPT to generate patchs and save them.
- `ov`: By setting it to `True`, you can ony verify the patched generated by ChatGPT.
- `bug_id` and `project`: If you both give these two parameters, you will request ChatGPT to generate patch for one bug them verify; If you only give `project`, you will request ChatGPT to generate patches for all bugs in this project then verify; If you don't give these two parameters, you will request ChatGPT to generate patches for all bugs in all projects then verify.
- `-s`: If you want run from a specific `bug_id`, you can set this parameter.
- `max_tokens`: The max length of the prompt you can sent to ChatGPT.
- `prompt_level`: We prepare some prompts for you, you can see `src/core/chatgpt/confg/prompt_config.py` for details.
- `prompt` : If you want to use your own designed prompt, you can set this parameter.
